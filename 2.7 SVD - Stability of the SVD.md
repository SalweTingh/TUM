## 2.7 Stability of the Singular Value Decomposition
What happens if we compute the SVD not of $A$, but of a slightly perturbed matrix $\tilde A = A+E$? Is the SVD of $\tilde A$ a good estimate of the SVD of $A$?

For now, consider Hermitian matrices ($A^H = A$).

Recall: Hermitian matrices have real eigenvalues and orthogonal eigenvectors, i.e. the *spectral theorem*.

> **Theorem 8.1** (Spectral Theorem)
> If $A^H = A$, there exists an orthonormal eigenbasis $\{v_1,\dots,v_k\}$ and *real* (possibly negative!) eigenvalues $\{\lambda_1, \dots, \lambda_n\}$ s.t. $$A = \sum_k \lambda_k v_k v_k^H.$$
> (This representation is called *spectral decomposition*).

Why is this equation *not* an SVD representation? Because $\lambda_k$ may be negative! It can be converted to an SVD by letting $u_k = v_k \text{sign}\lambda_k$ and $\sigma_k = |\lambda_k|$. I.e. the SVD is equal to the spectral decomposition up to signs.

### Weyl's Bounds
Assume $A = A^H$. Order the eigenvalues s.t. $\lambda_1 \geq \dots \geq \lambda_n$. Then it holds that:

$$\lambda_1(\tilde A)
= \max_{||v||_2 = 1} v^H(A + E)v
\leq \max_{||v||_2 = 1} v^H A v + \max_{||v||_2 = 1} v^H E v
= \lambda_1(A) + \lambda_1(E).$$

This result can be extended (by extending the chain of inequalities to the 2nd, 3rd etc. eigenvalues) to get the following theorem:

> **Theorem 8.2** (Weyl).
> Let $A, E$ be Hermitian. Let $k \in [n]$. Then
> $$\lambda_k(A) + \lambda_n(E) \leq \lambda_k(A + E) \leq \lambda_k(A) + \lambda_1(E)$$
> or, put differently, $\lambda_k(A+E) \in [\lambda_k(A) + \lambda_n(E), \lambda_k(A) + \lambda_1(E)]$.

###### #Proof of Weyl's Bounds (simple form):
First inequality: Let $\tilde A = \sum_k \tilde \lambda_k \tilde v_k \tilde v_k^H$. Choosing $v = \tilde v_1$ establishes "$\leq$". The "$\geq$" direction: Choose a maximizer $v$ and decompose it in the ONB $\{\tilde v_j\}_j$. Rest is left as an exercise #TODO.

### Stability of SVD for Hermitian Matrices
If the $\lambda_i$ are bounded in absolute value by $\sigma_1$, we get the corollary:

> **Corollary 8.3**
> If $|\lambda_n|, |\lambda_1| \leq |\sigma_1|$ and $A, E$ are Hermitian, then for all $k \in [n]$, $$|\sigma_k(A+E) - \sigma_k(A)| \leq ||E||$$

^357a1a

### Mirsky's Bounds
A generalization of [[#^357a1a|Corollary 8.3]] is Mirsky's theorem; a weaker form is given here:

> **Theorem 8.4 (Mirsky)**
> If $A, E$ are arbitrary matrices, then
> $$\sqrt{\sum_{k=1}^n |\sigma_k(A+E) - \sigma_k(A)|^2 \leq ||E||_F}$$

The original form of the theorem holds for an arbitrary *unitarily invariant* norm, including the spectral norm. As a consequence, [[#^357a1a|Corollary 8.3]] holds for arbitrary matrices.


### Stability of Singular Spaces: Principal Angles
The following notion generalizes the idea of $\cos \theta(v,w) = w^\top v$ for unit vectors to subspaces ("angles between subspaces").

> **Definition 8.5** (Principal Angles)
> Let $V, W \in \mathbb K^{J\times I}$ be orthogonal matrices spanning $n$-dim 
 subspaces $V, W$ of $\mathbb K^J$ (we may assume $n=|I| \leq |J| = d$). Define the *principal angles* between $V$ and $W$ by $$\cos \Theta(V, W) = \Sigma (W^H V),$$
 ==where $\Sigma(W^HV)$ is the list of singular values== of the matrix $W^H V$.

(Note the slight abuse of notation: subspace and its basis matrix use the same symbols $V, W$).


#### Principal Angles: Geometric Intuition
The principal angles, in a sense, quantify how different orthogonal projections to the two subspaces are: Recall $P_V = VV^H$, $P_W = WW^H$. Then:

> **Proposition 8.6**
> $$||P_V - P_W||_F = ||VV^H - WW^H||_F = \sqrt{2} ||\sin \Theta(V,W)||_2$$

^c84334

###### #Proof of [[#^c84334|Proposition 8.6]]
Use that the Frob. norm is generated by the scalar product. Using properties of the trace, we get:
$$||VV^H - WW^H||_F^2 = \text{tr} (VV^H - WW^H)^H(VV^H - WW^H)$$
$$\dots = \text{tr} (VV^H - WW^HVV^H -VV^HWW^H + WW^H)$$
%%$$\dots = \text{tr} (I - WW^H)VV^H + \text{tr} (I - VV^H)WW^H$$%%
$$\dots = n \text{tr} (W^H V V^H W) + n - \text{tr} (V^H W W^H V)
= 2^n - ||W^H V||_F^2$$
(using the cyclcity of the trace somehow? #TODO )
$$\dots = \sum_k (1 - \cos(\Theta(V,W)_k)^2)
= ||\sin \Theta(W, W)||_2^2$$

%% #Lecture 11, 20.06. [[Foundations Section 2.7 printout.pdf]] %%
#TODO check if anything was left out in this proof


#### Stability of singular spaces: Wedin's Bound
Define $E = \tilde A - A$. Fix $1 \leq k \leq r_{max} = \min(|I|, |J|)$ and split the SVD into two parts, a block of size $k$ and the rest:
$$A = (U_1, U_0)\text{diag}(\Sigma_1, \Sigma_0) (V_1^H, V_0^H)^\top = U_1 \Sigma_1 V_1^H + U_0 \Sigma_0 V_0^H.$$

Correspondingly, split the SVD of $\tilde A$.

Then $A + E = A_1 + A_0 + E = \tilde A_1 + \tilde A_0 = \tilde A$.

It hold that $range(A_1)$ is spanned by $U_1$ and $range(A_1^H)$ is spanned by $V_1$. Define *residual matrices* $R_{11} = A \tilde V_1 - \tilde U_1 \tilde \Sigma$ and $R_{21} = A^H \tilde U_1 - \tilde V_1 \tilde \Sigma^H$. The residual matrices and $E$ are connected by
$$R_{11} = A\tilde V_1 - \tilde U_1 \tilde \Sigma = (\tilde A - E) \tilde V_1 - \tilde U_1(\tilde U_1^H \tilde A \tilde V_1) = - E \tilde V_1.$$
Analgously, $R_{21} = -E^H \tilde U_1$.

> **Theorem 8.7 (Wedin's Bound)**
> Assume there are $\alpha \geq 0, \delta > 0$ s.t.
> $$\sigma_k(\tilde A) \geq \alpha + \delta ~~\text{and}~~ \sigma_{k+1}(A) \leq \alpha.$$
> Then for every unitarily invariant norm, in particular the spectral and Frobenius norm,
> $$\max\left(|| \sin \Theta(\tilde V_1, V_1)||, ||\sin \Theta(\tilde U_1, U_1)||\right)
\leq \frac{\max(||R_{11}||, ||R_{21}||)}{\delta} \leq \frac{||E||}{\delta}$$ (recall that $\Theta(\cdot, \cdot)$ is a vector, so $\sin$ is applied entry-wise here).

Some intuition: The norm of the angle between the two subspaces is bounded by the error matrices.