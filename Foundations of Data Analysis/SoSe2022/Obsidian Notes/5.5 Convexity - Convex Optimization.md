	## 5.5 Convex Optimization

#TODO (watched recording, but have to summarize the first few slides)
#TODO one important take-away: equality constraints can be assumed linear, as $-f$ convex and $f$ convex implies $f$ linear.

- Optimization problems
- Equality/Inequality constraints
- constrained/unconstrained problems
- convex and linear optimization problems

%% #Lecture 19, 18.07.  %%
[[Foundations Section 5.5 printout.pdf]]

Remark: convexity does not imply continuity - in particular, not true for extended-value functions! ( #Question is it true for real-valued functions?)

### Lagrange Function and Lagrange Dual
#### Lagrange function
The *Lagrange function* for an optimization of the above ( #TODO  link) form is defined as
$$L(x, \xi, \nu) = F_0(x) + \xi^\ast(Ax-y) + \sum_{l=1}^M \nu_l(F_l(x) - b_l),$$$$x \in \mathbb R^N, ~\xi \in \mathbb R^M, ~\nu_l \geq 0, ~l \in [M].$$
Without inequality constraints, it simplifies to
$$L(x, \psi) = F_0(x)+ \psi^\ast(Ax-y).$$
The variables $\xi, \nu$ are called *Lagrange multipliers*.

#### Lagrange Dual
The *Lagrange dual function* is $$H(\xi, \nu) = \inf_{x \in \mathbb R^N} L(x, \xi, \nu),$$
$\xi \in \mathbb R^m, \mu \in \mathbb R^M, \nu \succcurlyeq 0$. The $\inf$ takes  $-\infty$ if its argument is unbounded.

Without inequality constraints, it simplifies to $$H(\xi) = \inf_x L(x, \xi) = \inf (F_0(x) + \xi^\ast (Ax - y))$$
#### Lagrange Dual and Optimization
The Lagrange dual gives a lower bound on the optimal value of the minimization problem:
$$H(\xi, \nu) \leq F(x^\sharp)$$
###### #Proof of the Lagrange Dual lower bound
If $x$ is a feasible point, then $Ax - y =0$ and $F_l(x) \leq b_l$ for all $l$. So for all $\xi$ and $\nu \succcurlyeq 0$, , $$\xi^\ast (Ax-y) + \sum_l \nu_l(F_l(x) - b_l) \leq 0.$$
Therefore $L(x, \xi, \nu) = F_0(x) + \xi^\ast(Ax - y) + \sum_l \nu_l (F_l(x) - b_l)$. Taking the $\inf$ over all $x$ on the left and all feasible $x$ on the right shows the desired inequality.

### The Dual Problem
Goal: make the Lagrange dual bound as tight as possible. This motives the opt. problem:
$$\max H(\xi, \nu) ~~\text{s.t.}~~ \nu \succcurlyeq 0.$$
This optimization problem is called the *dual problem* to the above problem (which is called the *primal problem*). As $H$ is concave, we can turn this into the convex problem of minimizing $H$.

A pair $(\xi, \nu)$ s.t. $\nu \succcurlyeq 0$ is called *dual feasible*. A feasible maximizer $(\xi^\sharp, \nu^\sharp)$ of the dual problem is called the *dual optimal*, or the *optimal Lagrange mulitpliers.*

If $x^\sharp$ is optimal for the primal, then $(x^\sharp, \xi^\sharp, \nu^\sharp)$ is called *primal-dual optimal*.

#### Weak and Strong Duality
The *weak duality* holds: $$H(\xi^\sharp, \nu^\sharp) \leq F(x^\sharp).$$
For "most", but not all problems, the *strong duality* holds:
$$H(\xi^\sharp, \nu^\sharp) = F(x^\sharp).$$
> **Theorem 17.1** (*Slater's constraint qualification*)
> Let $F_0, \dots, F_M$ be convex functions, $dom(F_0) = \mathbb R^N$.
> If there is an $x$ s.t. $Ax = y$ and $F_l(x) < b_l$ for all $l$, then *strong duality holds*.
> In case there are no inequality constraints then strong duality holds if the primal is feasible, i.e. $\exists x: Ax=y$.

^573378

##### Saddle point interpretation
For simplicity, consider the primal without inequality constraints. Let $(x^\sharp, \xi^\sharp)$ be primal-dual optimal. By definition of the Lagrange function, we have
$$\sup_\xi L(x, \xi) = \sup_\xi (F_0(x) + \xi^\ast(Ax-y)) = \begin{cases}F_0(x), Ax=y \\ \infty, Ax \neq y\end{cases}.$$
So if $x$ is not feasible, the $\sup$ is $\infty$. Therefore, the feasible minimizer $x^\sharp$ of the primal satisfies $$F_0(x^\sharp) = \inf_x \sup_\xi L(x, \xi).$$
On the other hand, a dual optimal vector $\xi^\sharp$ satisfies $$H(\xi^\sharp) = \sup_\xi \inf_x L(x, \xi)$$
Hence by weak duality,
$$\sup_\xi \inf_y L(x, \xi) \leq \inf_x \sup_\xi L(x, \xi)$$
If strong duality holds,
$$\sup_\xi \inf_x L(x, \xi) = \inf_x \sup_\xi L(x, \xi)$$
In other words: *if strong duality holds, the order of minimization and maximization can be interchanged.* The is called the *strong max-min property*, or *saddle point property*. Indeed in this case, $(x^\sharp, \xi^\sharp)$ is a saddle point of $L$:
$$\forall x, \xi: ~~ L(x^\sharp, \xi^\sharp) \leq L(x^\sharp, \xi^\sharp) \leq L(x, \xi^\sharp)$$
> **Theorem 17.2**
> Consider two norms $||\cdot||$, $|||\cdot |||$. For $A, y$ and $\eta > 0$ consider the optimization problem $$\min_x |||x||| ~~\text{s.t.}~~||Ax-y||\leq \eta.$$
> Assume *strict feasibility*: $\exists x: ||Ax-y||<\eta$. Let $x^\sharp$ be a minimizer of the problem. Then for some $\lambda \geq 0$, $x^\sharp$ is a minimizer of $\min_x |||x||| + \lambda ||Ax - y||$.

^972a28

Example: $x^\ast = \arg\min ||x||_1$ where $||Ax-y||_2 \leq \eta$. Then there is a $\lambda$ s.t. the minimizer can be understood as the minimizer of another problem, $||x||_1 + \lambda ||Ax-y||$ (an unconstrained problem!).

###### #Proof of [[#^972a28|Theorem 17.2]]
One direction:
The Lagrange function of the considered problem is given by $L(x, \nu) = |||x||| + \nu(||Ax-y|| - \eta)$. By [[#^573378|Slater's qualification]], strong duality holds for the problem. Therefore there exists a dual optimal $\nu^\sharp \succcurlyeq 0$. The soddle point property implies taht $L(x^\sharp, \nu^\sharp) \leq L(x, \nu^\sharp)$ for all $x$. Therefore, $x^\sharp$ also minimizes $x \mapsto L(x, v^\sharp)$. Since the constant term $-v\sharp \eta$ does not affect the minimizer, the conclusion follows with $\lambda = \nu^\sharp$.

Other direction:
Let $x^\sharp$ minimize the given problem, let $\nu = \lambda$. Choose $\eta = ||Ax^\sharp - y||$. Then the Lagrange dual $H$ satisfies $H(\nu) = L(x^\sharp, \xi) = |||x^\sharp|||$. By weak duality, $H(\nu) \leq |||x|||$ for all feasible $x$. Since $x^\sharp$ is feasible by the choice of $\eta$, it follows that $x^\sharp$ minimizes the given problem.


### Typical form of convex optimization problem in data analysis
Consider a convex optimization of the form:
$$\min_x F(Ax) + G(x)$$
with $F, G$ convex extended-valued functions and $A \in \mathbb R^{m\times N}$.

Substituting $z=Ax$ yields an equivalent problem: $$\min_{x,z} F(z) + G(x) ~~\text{s.t.}~~Ax-z = 0$$
The (first version of the) problem has Lagrange dual
$$H(\xi) = \dots = -F^\ast(\xi) - G^\ast(-A^\ast \xi)$$
(using the [[5.3 Convexity - Convex Conjugate#5 3 The Convex Conjugate|convex conjugate]]) and the dual problem is then given by $$\max_\xi (-F^\ast(\xi) - G^\ast(-A^\ast \xi)).$$
> **Theorem 17.3**
> Let $F, G$ be proper (=? #TODO ) convex extended-valued functions with either $dom(F) = \mathbb R^m$ or $dom(G) = \mathbb R^N$ and there is an $x$ such that $Ax \in dom(F)$. Assume the optima in the considered problem's primal/dual are attained. Then *strong duality holds* in the form
> $$\min_x F(Ax) + G(x) = \max_\xi -F^\ast(\xi) - G^\ast(-A^\ast \xi).$$
> Furthermore, a primal dual optimum $(x^\sharp, \xi^\sharp)$ is a solution to the saddle point problem $$\min_x \max_\xi \langle Ax, \xi\rangle + G(x) - F^\ast(\xi).$$

^99ca56

###### #Proof of [[#^99ca56|Theorem 17.3]], second part (primal-dual optimum formula)
By strong duality, the saddle point property of the Lagrange function holds. The value of the Lagrange function in the primal-dual optimal point is the optimal vlaue of the min-max problem $\max_\xi \min_{x, z} F(z) - \langle \xi, z \rangle + G(x) + \langle A^\ast \xi, x \rangle$ $=\min_x \max_\xi -(\max_z \langle \xi, z\rangle - F(z)) + \langle A^\ast \xi, x \rangle + G(x)$
The $\min$ and $\max$ can be interchanged because $((x^\sharp, z^\sharp), \xi^\sharp)$ is a saddle point of $L(\langle x, z \rangle - \xi)$, then $(x^\sharp, \xi^\sharp)$ is a saddle point of $H(x, \xi) = \min_z L(\langle x, z \rangle, \xi)$.

By definition of the convex conjugate, this can be rewritten as $$\dots = \min_x \max_\xi \langle Ax, \xi \rangle + G(x) - F^\ast(\xi).$$
( #TODO check this proof, had to write this down very quickly)